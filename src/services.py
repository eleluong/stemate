from openai import OpenAI
import os 

from PIL import Image

client = OpenAI(
    api_key= os.getenv("OPENAI_API_KEY"),
    base_url= os.getenv("OPENAI_API_BASE_URL")
)

def generate(
    prompt: str,
    model: str = "gpt-4o"
) -> str:
    """Generate a response from the given prompt using the specified model.
    Args:
        prompt (str): The input prompt.
        model (str): The model to use for generation.
    Returns:
        str: The generated response.
    """
    response = client.chat.completions.create(
        model=model,
        messages=[
            {"role": "system", "content": "You are a helpful assistant. Generate thoroughly answer for given question."},
            {"role": "user", "content": prompt}
        ],
        max_tokens = 10000,
        reasoning_effort="low",
        top_p=0.7
    )
    return response.choices[0].message.content


def process_response(response: str) -> dict:
    """
    Process the response string to extract steps and final answer.
    Args:
        response (str): The response string from the model.
    Returns:
        dict: A dictionary containing the steps and final answer.
    """
    step_pattern = "## Step"
    answer_parttern = "## Final Answer:"
    steps = []
    current_step = ""
    answer = ""
    steps = []
    for i in response.split("\n"):
        if answer_parttern in i:
            answer = i.split(answer_parttern)[-1].strip() + "\n\n"
        elif step_pattern in i:
            if current_step.strip() != "":
                steps.append(current_step.strip())
            current_step = i.strip()+ "\n\n"
        else:
            current_step += i.strip() + "\n\n" 
    if current_step:
        steps.append(current_step.strip())
    return {
        "steps": steps,
        "answer": answer
    }

def solver(
    question: str,
    model: str = "gpt-4o"

) -> dict:
    """
    Solve the given question step-by-step using the specified model.
    Args:
        question (str): The question to be solved.
        model (str): The model to use for solving the question.
    Returns:
        dict: A dictionary containing the steps and final answer.
    """
    prompt = f"Solve the following problem step-by-step and provide the final answer:\n\n{question}"
    # response_template = """{{
    # "steps": [<list of solution steps, with calculation and reasoning>],
    # "answer": <final answer>
# }}"""
    response_template = """## Step 1: 
...
## Step 2:
...

## Final Answer: <final answer (number or choice only, no sign or text, e.g., if answer is 42, just write 42, if answer is choice B, just write B)>
    """
    response = generate(prompt + "\n\nResponse exactly like below template, say nothing else.\n" + response_template, model=model)
    print(f"Raw response from model {model}: {response}")
    if "</think>" in response:
        response = response.split("</think>")[-1].strip()

    return process_response(response)  # Using eval for simplicity; consider safer parsing in production


teaching_methods = {
    "Lecture/Direct Instruction": "Teacher explains the solution step by step in a clear, structured way.",
    "Socratic/Questioning": "Teacher guides the solution by asking targeted questions instead of giving direct answers.",
    "Problem-Based/Inquiry": "Teacher lets students try first, then explains by highlighting reasoning and connecting to the correct solution.",
    "Demonstration": "Teacher works through the solution while verbalizing thought processes and showing methods.",
    "Collaborative/Peer Teaching": "Teacher listens to student explanations and steps in to clarify or model the correct solution.",
    "Flipped Classroom": "Teacher reinforces the solution in class by clarifying misconceptions and deepening understanding of pre-learned steps."
}

chacteristics_examples = {
    "Mr. Rogers": "Kind and patient, always encouraging you to try your best.",
    "The Genie from Aladdin": "Magical and fun, making learning feel like an adventure.",
    "Dumbledore": "Wise and thoughtful, guiding you gently through challenges.",
    "Doraemon": "A futuristic cat robot who pulls out gadgets to solve any problem.",
    "Hermione Granger": "Brilliant, diligent, and always ready with the right book or spell.",
    "Sherlock Holmes": "Analytical and logical, teaching you how to think step by step.",
    "Yoda": "Wise mentor who guides with patience and cryptic but powerful lessons.",
    "Winnie the Pooh": "Gentle and kind, helping you approach challenges calmly and without stress.",
    "Baymax": "Caring, supportive, and always checking if youâ€™re okay before tackling tough work.",
    "Tony Stark": "Tech genius who mixes humor with sharp problem-solving.",
    "Mulan": "Brave and determined, showing how persistence leads to mastery.",
    "Albert Einstein": "Playful scientist who makes complex ideas approachable.",
    "SpongeBob SquarePants": "Energetic, curious, and never afraid to ask 'why?' over and over."
}



def personalized_explanation(
    question= "",
    processed_response = {},
    lecturing_method = "Socratic/Questioning",
    characteristic = "Yoda",
    language = "Vietnamese",
    model: str = "gpt-4o"
) -> dict:
    """
    Generate a personalized explanation of the solution steps based on the user's level.
    Args:
        processed_response (dict): The processed response containing steps and answer.
        user_level (str): The user's level (e.g., "high school", "college").
        model (str): The model to use for generating the explanation.
    Returns:
        dict: A dictionary containing the personalized explanation.
    """
    steps = processed_response.get("steps", [])
    answer = processed_response.get("answer", "")
    if not steps or not answer:
        return processed_response
    # prompt = f"Explain the following solution steps of the following question in a {characteristic} manner using {lecturing_method} method. Make it easy to understand and engaging.\n\nQuestion: {question}\n\nSteps:\n" + "\n".join(steps) + f"\n\nFinal Answer: {answer}\n\nTeaching Method Description: {teaching_methods.get(lecturing_method, '')}\n\n"
    prompt = f"You are {characteristic}, a tutor who is {chacteristics_examples.get(characteristic, '')}. Explain the following solution steps of the following question in a {characteristic} manner using {lecturing_method} method. Make it easy to understand and engaging.\n\nQuestion: {question}\n\nSteps:\n" + "\n".join(steps) + f"\n\nFinal Answer: {answer}\n\nTeaching Method Description: {teaching_methods.get(lecturing_method, '')}\n\n"

    response_template = """## Solution:
<Solution with detailed explanation>
...

## Final Answer: <final answer (number or choice only, no sign or text, e.g., if answer is 42, just write 42, if answer is choice B, just write B)>
    """

    response_language = f"\n\nThe explanation should be in {language}.\n"
    response = generate(prompt + response_template + response_language + "Response:", model=model)
    return response

def image_parser(
    image_str: str,
    model: str = "gpt-4o"
) -> str:
    """
    Parse the image to extract question, choices and context in markdown format.
    Args:
        image_str (str): The base64 encoded string of the image.
        model (str): The model to use for parsing the image.
    Returns:
    str: The extracted question, choices and context in markdown format.
    """
    chat_ = [
        {"role": "system", "content": "You are a helpful assistant that can analyze images."},
        {
            "role": "user", 
            "content": [
                {"type": "text", "text": "Extract question, choices and context (if existed) of the question in markdown from the image. Keep the language same as in the image. Say nothing else such as related fomula or answer."},
                {
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/png;base64,{image_str}",
                    },
                },
            ],
        }
    ]
    response = client.chat.completions.create(
        model=model,
        messages=chat_,
        top_p=0.7,
    )
    return response.choices[0].message.content


def question_generator(
    sample_question = "",
    level = "high school",
    model: str = "gpt-4o",
    num_question: int = 3
):
    """
    Generate a new question similar to the sample question for the specified level.
    Args:
        sample_question (str): The sample question to base the new question on.
        level (str): The level of the students (e.g., "high school", "college").
        model (str): The model to use for generating the question.
    Returns:
        str: The generated question.
    """
    prompt = f"Generate {num_question} new question similar to the following question for {level} students. The new question should be different in context but similar in language, difficulty level and structure. Provide the questions in markdown format.\n\nSample Question:\n{sample_question}\n\nSay nothing else.\n\nResponse Template:"
    response_template = """## Question 1:
...
## Question 2: 
..."""
    response = generate(prompt + response_template + "New Questions:", model=model)

    print(response)
    return response